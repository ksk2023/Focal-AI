"""
AI Photography Director - å§¿åŠ¿å½•åˆ¶å·¥å…·
ç”¨äºå½•åˆ¶å’Œä¿å­˜è‡ªå®šä¹‰å§¿åŠ¿åˆ° poses.json
"""

import cv2
import json
import numpy as np
import mediapipe as mp
from datetime import datetime


def record_pose():
    """
    å½•åˆ¶å§¿åŠ¿å·¥å…·
    - æŒ‰ 's' ä¿å­˜å½“å‰å§¿åŠ¿
    - æŒ‰ 'q' é€€å‡º
    """
    
    # åˆå§‹åŒ– MediaPipe
    mp_pose = mp.solutions.pose
    mp_drawing = mp.solutions.drawing_utils
    
    pose = mp_pose.Pose(
        static_image_mode=False,
        model_complexity=1,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
    
    if not cap.isOpened():
        print("âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´")
        return
    
    print("=" * 50)
    print("ğŸ“¸ å§¿åŠ¿å½•åˆ¶å·¥å…·")
    print("=" * 50)
    print("æ“ä½œè¯´æ˜ï¼š")
    print("  [s] - ä¿å­˜å½“å‰å§¿åŠ¿")
    print("  [q] - é€€å‡ºç¨‹åº")
    print("=" * 50)
    
    # åŠ è½½ç°æœ‰ poses.json
    poses_file = "poses.json"
    try:
        with open(poses_file, 'r', encoding='utf-8') as f:
            poses_data = json.load(f)
    except FileNotFoundError:
        poses_data = {}
    
    current_landmarks = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # ç¿»è½¬å›¾åƒï¼ˆé•œåƒï¼‰
        frame = cv2.flip(frame, 1)
        
        # è½¬æ¢é¢œè‰²
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # æ£€æµ‹å§¿æ€
        results = pose.process(rgb_frame)
        
        if results.pose_landmarks:
            # ç»˜åˆ¶éª¨éª¼
            mp_drawing.draw_landmarks(
                frame,
                results.pose_landmarks,
                mp_pose.POSE_CONNECTIONS
            )
            
            # ä¿å­˜å½“å‰å…³é”®ç‚¹
            current_landmarks = [
                [lm.x, lm.y, lm.z] for lm in results.pose_landmarks.landmark
            ]
            
            # æ˜¾ç¤ºçŠ¶æ€
            cv2.putText(frame, "Pose Detected! Press 's' to save", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        else:
            cv2.putText(frame, "No pose detected", 
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
        
        # æ˜¾ç¤ºå·²ä¿å­˜çš„å§¿åŠ¿æ•°é‡
        cv2.putText(frame, f"Saved poses: {len(poses_data)}", 
                   (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        cv2.imshow("Pose Recorder", frame)
        
        key = cv2.waitKey(1) & 0xFF
        
        if key == ord('s') and current_landmarks:
            # ä¿å­˜å§¿åŠ¿
            pose_name = input("\nè¯·è¾“å…¥å§¿åŠ¿åç§°(è‹±æ–‡ï¼Œå¦‚ my_pose): ").strip()
            pose_desc = input("è¯·è¾“å…¥å§¿åŠ¿æè¿°(ä¸­æ–‡): ").strip()
            
            if pose_name:
                poses_data[pose_name] = {
                    "name": pose_desc or pose_name,
                    "description": pose_desc or f"è‡ªå®šä¹‰å§¿åŠ¿ - {pose_name}",
                    "landmarks": current_landmarks
                }
                
                # ä¿å­˜åˆ°æ–‡ä»¶
                with open(poses_file, 'w', encoding='utf-8') as f:
                    json.dump(poses_data, f, indent=2, ensure_ascii=False)
                
                print(f"âœ… å·²ä¿å­˜å§¿åŠ¿: {pose_name}")
                print(f"   å…± {len(poses_data)} ä¸ªå§¿åŠ¿")
            
        elif key == ord('q'):
            break
    
    cap.release()
    cv2.destroyAllWindows()
    print("\nğŸ‘‹ å½•åˆ¶å®Œæˆï¼")


if __name__ == "__main__":
    record_pose()
